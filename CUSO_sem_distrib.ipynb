{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwauquier/CUSO_dsm_tutorial/blob/main/CUSO_sem_distrib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuQbw0bzaUiN"
      },
      "source": [
        "# SECTION 1 - Manipulation d'espaces vectoriels\n",
        "\n",
        "Ce tutoriel propose d'utiliser gensim, une implémentation Python de Word2Vec, pour manipuler des modèles distributionnels. Pour plus d'informations sur gensim, et pour aller plus loin dans l'utilisation de cette librairie, visitez la [documentation en ligne](https://radimrehurek.com/gensim/models/word2vec.html), ou les [tutoriels dédiés](https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6l_LWeMe7qo"
      },
      "source": [
        "On commence par charger la librairie `gensim`, c'est-à-dire l'ensemble des ressources, codes et fonctions nous permettant de manipuler les espaces vectoriels. Cela se fait à l'aide de la commande `import`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVe67v_7yreZ"
      },
      "outputs": [],
      "source": [
        "# On charge la librairie gensim\n",
        "\n",
        "import gensim.models.keyedvectors as word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uZs8vene45x"
      },
      "source": [
        "Il nous faut maintenant charger l'espace vectoriel (ou modèle distributionnel) sur lequel on souhaite travailler. Nous travaillerons ici avec des modèles directement mobilisables en ligne, pour des raisons pratiques - les modèles sont souvent des fichiers assez lourds, dont le transfert et le téléchargement peuvent être longs.\n",
        "\n",
        "Pour cela, on va utiliser le module `downloader` de gensim qui nous permet d'accéder à des modèles disponibles en ligne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "191hki6WJUmG"
      },
      "outputs": [],
      "source": [
        "# On charge le module 'downloader' pour accéder aux modèles en ligne\n",
        "\n",
        "import gensim.downloader\n",
        "\n",
        "# La commande ci-dessous permet d'afficher le nom des modèles disponibles et que l'on peut charger\n",
        "\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bZWSzv4gGCQ"
      },
      "source": [
        "Il nous suffit alors de choisir le modèle de notre choix  - on travaillera ici avec un modèle Word2vec, donc commençant par la mention *'word2vec'*. Les deux seuls corpus à ce titre étant donc 'word2vec-ruscorpora-300' et 'word2vec-google-news-300', nous choisirons ce dernier pour des raisons de lisibilité.\n",
        "\n",
        "Il nous suffit donc de charger le modèle à l'aide de la fonction `gensim.downloader.load()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3NrgMMUJhKW"
      },
      "outputs": [],
      "source": [
        "# On charge le modèle de notre choix dans la variable w2v_vectors\n",
        "# Il nous suffira alors de faire appel à cette variable pour interroger le modèle\n",
        "\n",
        "# Attention, le chargement peut être long !\n",
        "\n",
        "w2v_vectors = gensim.downloader.load('word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVniYQoiilp_"
      },
      "source": [
        "L'espace vectoriel est désormais sauvegardé dans la variable *w2v_vectors*. Nous pouvons donc désormais l'interroger.\n",
        "\n",
        "L'utilisation primaire d'un espace vectoriel est d'interroger la similarité distributionnelle (et donc par extension sémantique) de deux mots. Pour cela, on utilise la fonction `similarity()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGMf2ez6L63t"
      },
      "outputs": [],
      "source": [
        "# On utilise la fonction 'similarity()' pour évaluer la proximité distributionnelle entre deux mots\n",
        "\n",
        "w2v_vectors.similarity('WORD1','WORD2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WEzxZ1Qi4-8"
      },
      "source": [
        "On peut plus largement identifier les *n* voisins distributionnels d'un mot cible, c'est-à-dire les *n* mots ayant les vecteurs les plus similaires à celui de notre mot cible. Pour cela, on utilise la fonction `most_similar()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWs1aw7YbV8u"
      },
      "outputs": [],
      "source": [
        "# On utilise la fonction 'most_similar()' pour trouver les voisins distributionnels d'un mot\n",
        "\n",
        "w2v_vectors.most_similar('WORD', topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCoHoGLLjFgs"
      },
      "source": [
        "Dans l'absolu, on peut récupérer le vecteur d'un mot, c'est-à-dire ses coordonnées. Cela est notamment utile si l'on veut le réinjecter dans une autre chaîne de traitement (classification, clustering...). Mais cet objet est en lui-même difficile à interpréter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGybXxMlPqOh"
      },
      "outputs": [],
      "source": [
        "# On récupère le vecteur lui-même (ses coordonnées) de la façon suivante\n",
        "\n",
        "vec = w2v_vectors['WORD']\n",
        "\n",
        "# Mais comme on peut le voir, le vecteur est difficilement interprétable par lui-même\n",
        "print(vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg6V_TxtjY-Q"
      },
      "source": [
        "Parmi les fonctions comprises dans la librairie `gensim` pour explorer l'espace vectoriel, on retrouve par exemple la fonction `doesnt_match`, qui permet d'identifier dans une liste de mots un intrus sur la base de ses propriétés distributionnelles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8ihwzDBRQLL"
      },
      "outputs": [],
      "source": [
        "# Parmi les petites fonctionnalités complémentaires, on peut identifier l'intrus dans une liste à l'aide de la fonction 'doesnt_match()'\n",
        "\n",
        "print(w2v_vectors.doesnt_match(['WORD1', 'WORD2', 'WORD3', 'WORD4', 'WORD5', 'WORD6']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp3w8ApojtKQ"
      },
      "source": [
        "On peut aussi complexifier un peu les fonctions de base, telle que `most_similar`, pour réaliser des tâches plus complexes. C'est notamment le cas de l'analogie (qu'est ce qui est à C ce que A est à B ?), que l'on peut représenter mathématiquement comme une équation de type `A - B + C = D`, où A, B, C et D sont des vecteurs. La fonction nous rapporte alors les mots qui répondent le mieux à ce qui est attendu de D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZwnXSymRQrY"
      },
      "outputs": [],
      "source": [
        "# On peut aussi compléter une analogie en reprenant la fonction 'most_similar()'\n",
        "# L'idée est ici de répondre à la question : \"quel est l'élément D qui est à l'élément C ce que l'élément A est à l'élément B ?\"\n",
        "# Qu'on peut traduire par A - B + C = D\n",
        "# où A et C seront donc les deux mots que l'on mettra en \"positive\", B le mot en \"negative\", et D la réponse que nous retournera la fonction\n",
        "\n",
        "w2v_vectors.most_similar(negative=['WORD1'],positive=['WORD2', 'WORD3'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZClCbC_AmOnS"
      },
      "source": [
        "Vous pouvez ci-dessous essayer de faire vos propres requêtes et notamment : \n",
        "* Quels sont les voisins de *stock* ?\n",
        "* Quels sont les voisins de *schtroumpf* ?\n",
        "* Quelle est la proximité distributionnelle des paires suivantes ?\n",
        "  * *good* et *bad*\n",
        "  * *dog* et *beagle*\n",
        "  * *game* et *play*\n",
        "* Quels sont les voisins de *mouse* ?\n",
        "\n",
        "Quelles conclusions tirez-vous de ces quelques exemples ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KvEpuBxNYOQ"
      },
      "source": [
        "# SECTION 2 - Entraînement de modèles\n",
        "\n",
        "Entraîner (ou construire) un modèle distributionnel correspond au calcul des coordonnées des vecteurs à partir d'un corpus. L'entraînement d'un modèle n'est pas complexe.\n",
        "\n",
        "Attention, le processus peut être plus ou moins long en fonction de votre machine (ou de celle du serveur sur lequel vous travaillez). Nous travaillerons ici avec de (tout) petits corpus, donc cela ne devrait pas prendre plus de quelques minutes.\n",
        "\n",
        "Le système prend en entrée des phrases (des listes de mots) dans un fichier texte (.txt), et retourne un modèle (une liste de vecteurs). Dans les faits, nous allons lui fournir un fichier contenant une phrase par ligne, et où chaque mot est tokenisé.\n",
        "\n",
        "Nous utiliserons pour commencer les corpus disponibles en ligne dans le Project Gutenberg. Pour cela, nous commençons par importer les librairies nécessaires."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7WQS-o1HTP2"
      },
      "outputs": [],
      "source": [
        "# Importation des librairires\n",
        "# Ces librairies ne concernent que l'importation et le traitement des corpus du Project Gutenberg, et ne dépendent donc absolument pas de gensim\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cela va nous permettre de télécharger des corpus disponibles en ligne, dont voici la liste (*a priori*) exhaustive : 'austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt',\n",
        "'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt',\n",
        "'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt',\n",
        "'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt',\n",
        "'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt',\n",
        "'shakespeare-macbeth.txt', 'whitman-leaves.txt'\n",
        "\n",
        "Choisissez dans cette liste le corpus de votre choix, et notez bien son nom complet.\n",
        "\n",
        "Ces corpus sont cependant au format brut (sans aucun traitement). Vous pouvez le voir en imprimant les premières lignes du texte."
      ],
      "metadata": {
        "id": "JhWpeEFFyzvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = gutenberg.raw('XXX.txt')\n",
        "print(text[:400]) # Nous imprimons ici les 400 premiers caractères du texte brut sauvegardé dans la variable \"text\""
      ],
      "metadata": {
        "id": "6wDM2WKpzWE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le système ne prend cependant pas un texte brut (non traité), mais des listes de mots. Nous devons donc appliquer un minimum de traitement à notre corpus.\n",
        "\n",
        "La librairie `nltk` propose directement une fonction permettant de traiter ses corpus, `gutenberg.sents()`"
      ],
      "metadata": {
        "id": "78r7016pzWRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = gutenberg.sents('XX.txt')"
      ],
      "metadata": {
        "id": "QuUwl4KI0A7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il ne reste plus qu'à entraîner le modèle à l'aide de la fonction `gensim.models.Word2Vec()`"
      ],
      "metadata": {
        "id": "-LogTjTl0BtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_default = gensim.models.Word2Vec(corpus)"
      ],
      "metadata": {
        "id": "Iqf9BwZL0LMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Votre modèle est ici enregistré dans la variable *model_default*. Vous pouvez ainsi directement la mobiliser"
      ],
      "metadata": {
        "id": "gwBdtbU60Tfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_default.wv.similarity(\"WORD1\",\"WORD2\")"
      ],
      "metadata": {
        "id": "QKkRD9Jy0RsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notez ici l'utilisation du préfixe wv pour appeler la fonction. Cela est notamment dû aux différentes fonctions d'entraînement de Word2Vec avec gensim\n",
        "\n",
        "Notez que cela ne s'utilise que si vous travaillez sur un modèle que vous venez tout juste d'entraîner dans votre instance, pas avec un modèle que vous importez (comme on le faisait précédemment).\n",
        "\n",
        "Notez par ailleurs, comme son nom l'indique, que vous avez ici entraîné un modèle par défaut. Nous n'avons renseigné aucun paramètre autre que le corpus. Les hyper-paramètres ont donc des valeurs par défaut : dimensions des vecteurs = 100, fenêtre de 5, seuil de fréquence minimale de 5, CBOW.\n",
        "\n",
        "Si on veut entraîner un modèle sur notre corpus avec un seuil de fréquence de 50, des vecteurs à 200 dimensions, une fenêtre de 3, et l'utilisation de l'architecture SkipGram, on utilisera la commande :"
      ],
      "metadata": {
        "id": "2H0xikdc0Y6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_advanced = gensim.models.Word2Vec(corpus, min_count=50, vector_size=200, window=3, sg=1)"
      ],
      "metadata": {
        "id": "GiUcVqw30v7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mais vous pouvez évidemment choisir les valeurs que vous souhaitez.\n",
        "\n",
        "Vous pouvez aussi, si vous le souhaitez, entraîner un modèle à partir du petit corpus (extrait du BNC) présent dans le Drive associé à ce notebook. Pour cela, il faudra d'abord donner l'accord au notebook d'explorer le contenu du Google Drive. \n",
        "\n",
        "Notez que cette autorisation ne vaut que pour cette instance (elle est à renouveler à chaque utilisation du notebook), et le présent code n'amène à la modification d'aucun document."
      ],
      "metadata": {
        "id": "JlZSfNKg0wiB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yi0VA6y7pun"
      },
      "outputs": [],
      "source": [
        "# Code valable si vous travaillez en ligne sur le notebook Colab\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Il suffit alors d'utiliser la fonction `LineSentence()` de `gensim` (similaire à `guntenberg.sents()`) sur le corpus que vous indiquerez."
      ],
      "metadata": {
        "id": "kl6Uu9ON1Skj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.word2vec import LineSentence\n",
        "\n",
        "corpus_bnc = LineSentence('/content/drive/MyDrive/CUSO_2022_semantique_distributionnelle/tiny_sample_bnc.txt')"
      ],
      "metadata": {
        "id": "Ged4Wi8V1VX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez alors entraîner le modèle, comme précédemment, avec ou sans paramètres spécifiques."
      ],
      "metadata": {
        "id": "0fwOBl_s1-QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_default_bnc = gensim.models.Word2Vec(corpus_bnc)"
      ],
      "metadata": {
        "id": "VAAwuojP2A3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez dès lors comparer les représentations construites sur les différents corpus et/ou avec les différents paramètres. Par exemple, quels sont dans vos différents modèles les voisins de *man* ? Et de *stock* ?\n",
        "\n",
        "Pour le moment, le modèle n'est enregistré que dans votre variable. Si vous fermez le programme, votre modèle disparaît. Vous n'aurez par ailleurs jamais strictement le même modèle.\n",
        "\n",
        "Vous pouvez sauvegarder et exporter votre modèle avec la fonction `save()`"
      ],
      "metadata": {
        "id": "ixSjSPBg2Bh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_vectors = model_default.wv\n",
        "word_vectors.save(\"word2vec_default.wordvectors\")"
      ],
      "metadata": {
        "id": "joaDwhod2Wqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle peut alors être rechargé dans un programme avec la fonction `load()` vue précédemment."
      ],
      "metadata": {
        "id": "s_hnlKSu2ZKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.KeyedVectors.load_word2vec_format('word2vec_default.wordvectors)"
      ],
      "metadata": {
        "id": "YY01lFLL2bLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SECTION 3 - fastText"
      ],
      "metadata": {
        "id": "kPyynGlPFLID"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous pouvez tester un modèle fastText en chargeant celui via `gensim.downloader()` : `fasttext-wiki-news-subwords-300`."
      ],
      "metadata": {
        "id": "3F6UWXj0FN0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
      ],
      "metadata": {
        "id": "OapPxqE9FYFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce modèle s'utilise de la même façon que les modèles word2vec."
      ],
      "metadata": {
        "id": "AS_J8VLJF3E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model.similarity('WORD1', 'WORD2')"
      ],
      "metadata": {
        "id": "xlHu1-omF3Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fastText_model.most_similar('WORD')"
      ],
      "metadata": {
        "id": "ZnQz69OiIm1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}